---
title: "Problem Set 4"
author: "Jacob Hood"
date: 'Due: Saturday, May 8th, 11:59 pm'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(pacman)
p_load(kableExtra, tidyverse, stargazer, plm, MASS, foreign, tibble)
```

# Part 1 Forensic Statistics and the Chi-Square Test  

Human beings are very bad at making up numbers. If you are told to come up with a sequence of random numbers, you will likely end up following some sort of pattern that is far from being random. For example, to pretend that your are selecting numbers at random, you will tend to pick "random-looking" numbers like 48 more often than "nonrandom-looking" numbers like 100. Picking "random-looking" numbers more often than "nonrandom-looking" ones is something that shouldn't occur randomly. The Chi-Square test provides us with a useful framework to formally detect this. One of its many applications is the detection of election fraud.  
  
  Imagine that you are part of a team of international observers that has been called to assess whether there is evidence of fraud in a general election that took place in a foreign country. Two candidates were on the ballot: Candidate A (the incumbent) and Candidate B. Candidate A won the election with 62% of the votes. One week after the election, some raised concerns about the validity of this result and suggested the possibility that election fraud could have occurred.^[These are real data from the Iranian election that was held on June 12, 2009. This exercise has been inspired by one example used by Dan Levy in his "Advanced Quantitative Methods" course at the Harvard Kennedy School.]  
  
  The setting is the following. There were 116 voting stations across the country. Each voting station has sent you the count of votes that went to Candidate A. To assess election fraud, you will be evaluating the frequency with which the final digit in each of these counts appears in the data. The table below shows precisely this. The first column list all values that the last digit in a vote count can take on (0 to 9). For example, if the number of votes that went to Candidate A in voting station #24 was 659, the final digit of this vote count would be 9. The second column tells you the frequency with which each final digit appeared across all voting stations. Among the 116 voting stations, 11 reported a number of votes for Candidate A that ended in 1, 8 reported a number of votes for Candidate A that ended in 2, and so on.
  
  
  
```{r , echo=FALSE}

tbl <- tibble(`Final Digit` = c(seq(1, 9, 1), 0, "Total"),
              `Observed Count` = c(11, 8, 9, 10, 5, 14, 20, 17, 13, 9, 116))
              
tbl %>% kbl(booktabs = T, align = "c") %>% kable_styling(full_width = F)
```
  
  Answers the questions below:  
  
  1. If the election results had not been manipulated (i.e., fraud did not occur), what would be your best guess for the number of voting stations that reported a vote count for Candidate A ending in 1? And in 6? And in 9?

Ending in 1: $f^e$ = (11/116)(11) = 11.6
Ending in 6: $f^e$ = (14/116)(14) = 11.6
Ending in 9: $f^e$ = (13/116)(13) = 11.6
  
  
  2. If the election results had not been manipulated, what is the probability that a vote count for Candidate A ended in1? And in 6? And in 9?  
Ending in 1: 11.6 out of 116 or = 0.1
Ending in 6: 11.6 out of 116 or = 0.1
Ending in 9: 11.6 out of 116 or = 0.1
  
  3. Following the logic from questions 1 and 2, complete columns 3 to 5 in the table below.
  
```{r , echo = F}

tbl2 <- tibble(`Final Digit` = c(seq(1, 9, 1), 0, "Total"),
              `Observed Count` = c(11, 8, 9, 10, 5, 14, 20, 17, 13, 9, 116),
              `Observed Share` = c(11/116, 8/116, 9/116, 10/116, 5/116, 14/116, 20/116, 17/116, 13/116, 9/116, 116/116) %>% round(digits =2),
              `Expected Count` = c(11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 11.6, 116),
              `Expected Share` = c(rep(11.6/116, 10), 1.00),
              `Chi-Square Stat` = c(0.03, 1.12, 0.58, 0.22, 3.76, 0.50, 6.08, 2.51, 0.17, 0.58, sum(0.03, 1.12, 0.58, 0.22, 3.76, 0.50, 6.08, 2.51, 0.17, 0.58) )
              )
              
tbl2 %>% 
  kbl(booktabs = T, align = "c") %>% 
  kable_styling(latex_options = "striped", full_width = F)

```

  4. Do the expected counts and shares match the observed ones? Just by looking at these discrepancies, are you able to determine whether fraud occurred? 
  
**Our observed counts do no match our expected counts. However, we are not able to determine whether fraud occured from just looking at raw count distributions. Chi-Square test is needed to determine statistcal indepdence or dependence.** 
  
  5. Formally define the null and alternative hypotheses for the test of "no fraud" in that election.
  
  **$H_0$ = The final digit of the vote count across voting stations and the observed count are statistically independent.**
  **$H_a$ = The final digit of the vote count across voting stations and the observed count are statistcally dependent**
  
  6. Calculate the $\chi^2$ statistics for each row in the table (Column 6). Keep in mind that the $\chi^2$ statistic is computed form counts, not from proportions. 
  
```{r}
#calculating chi-squared fro each row
# create data frame 
df <- tibble(final_digit = c(seq(1, 9, 1), 0),
              observed_count = c(11, 8, 9, 10, 5, 14, 20, 17, 13, 9),
             expected_count = c(rep(11.6, 10)))

# calculate by row
# create  variable for chi-squared, rounded to 2 decimal places
df <- df %>%
  rowwise() %>% 
  mutate(
    chi_squared = ((observed_count - expected_count)^2)/expected_count
    ) %>%
  round(digits = 2)

df$chi_squared
```
  

  7. Calculate the $\chi^2$ statistic for the entire distribution of outcomes and calculate the p-value.
```{r}
total_chi_sq <- sum(df$chi_squared)
total_chi_sq
p_value <- pchisq(total_chi_sq, df=9, lower.tail=F)
p_value
```
  

  8. Do you reject or fail to reject the null hypothesis of no fraud (use significance level $\alpha$ = .05).
  
**Because the p-value > .05 (.077), we fail to reject the null hypothesis of no fraud. **

  9. Write 3 paragraphs reporting your findings and explaining the logic that you followed to detect fraud in this election. You are writing this to someone who understands the concepts of sampling and ran- domness, but does not know what a Chi-Square test is. Imagine that this analysis is part of an academic article, and you have been invited to write a non-technical summary of your findings for the Upshot or Wonkblog.

```{r }

In order to determine if election fraud happened, we need to determine if the last digit of each count is really randommly distributed across voting stations. Even if the numbers might look off at first glance - meaning non-random - this might not hold true after statistical tests. If there was no election fraud, then we can expect that the last digit of the vote count for Candidate A across all voting stations is statistcally indepdent from teh count we actially observe. 

Chi-Squre test can help us determine statistical indepedence. 

```

# Part 2: Fixed-Effects Model

In this exercise, we use the dataset `sibling_data.dta` to study the effect of mother experiencing stress in pregnancy on child’s birth weight. All variables are described in the table below.
  
Variable Name|  Variable Detail
------------|----------------------------
 *Group Variable* | 
 `householdid` | Unique household id; Siblings from the same household share the same household id
               |
 *Dependent Variable* | 
 `birthwt`   | birth weight measured in pounds  
              |
 *Independent Variable* | 
 `stress`    | Whether or not mother experienced stress in preganacy (Yes=1; No=0)
 `age`       | Age
 `female`    | Female=1; Male=0
 `magebirth` | Mother’s Age at Birth
 `numsibling`| Number of Sibling
 `meduy`    | Mother’s Years of Schooling
 `feduy`    | Father’s Years of Schooling
 

1. Including all independent variables, build an OLS model and a fixed-effects model (use the `plm` R package);
```{r}
sibling_data <- read.dta("sibling_data.dta")

olsmodel<- lm(birthwt ~ stress + female + magebirth + numsibling + meduy + feduy, data = sibling_data)
femodel <- plm(birthwt ~ stress + female + magebirth + numsibling + meduy + feduy, data = sibling_data, model = "within", index = c("householdid"))
```

2. Summarize regression results in a table;
```{r}
stargazer(olsmodel, femodel, type = "text")
```

3. Interpret the coefficient of `stress` in the OLS model;
**For mothers that experienced stress during pregnancy, their children's birthweight decrease by 0.651 units, holding all else constant**

4. Interpret the coefficient of `stress` in the fixed-effects model; 

**For mothers that experienced stress during pregnancy, their children's birthweight decreased by 0.641 units, holding all else constant**

5. Interpret the coefficient of `magebirth` in the fixed-effects model;  

**For a one unit increase in mother's age at brith, their children's birthweight increase by 0.049 units**

6. Why don’t we get coefficients of `meduy`, `feduy`, and `numsibling` in the fixed-effects model?

**Coefficients are not included for these variable because there is likely missing data**

7. Perform a F-test to compare models and interpret outputs (use `pFtest` from the `plm` R package);
```{r}
pFtest(femodel, olsmodel)
```

8. Compared to an OLS model, what are the benefits of using a fixed-effect model?  


**OLS models aggregate (or pool) data, so they cannot account for individual-specific differences like fixed effects models can. Most importantly, fixed-effects models allow us to examine the effects of specific variables over time (using panel data). When we assume that individual factors might bias our variables of interest (i.e., children's birthweight), fixed-effect models are useful.**

# Part 3 Random-Effects Model

Let’s continue our discussions about estimating the effect of mother experiencing stress in pregnancy on birth weight.  

1. Including all independent variables, build a random-effects model (use the `plm` R package);  
```{r}
remodel <- plm(birthwt ~ stress + female + magebirth + numsibling + meduy + feduy, data = sibling_data, model = "random", index = c("householdid"))
```

2. Summarize regression results from OLS, fixed-effects, and random-effects models in a table;
```{r}
stargazer(olsmodel, femodel, remodel, type = "text")
```

3. How does the coefficient of `stress` change across models? What could be the potential causes that lead to these changes?  

4. Why do we get coefficients of `meduy`, `feduy`, and `numsibling` in the random-effects model?  

5. Perform a Hausman test to compare fixed-effects and random-effects models (figure out how to use the `phtest` function from the `plm` R package; you might look into the help page and examples by typing ?plm::phtest into your console)
```{r}
phtest(femodel, remodel, model = c("within", "random"),
)
```

  
  (a) What is the null hypothesis of this model? What is the alternative hypothesis?
  
  The null hypothesis of this model is that there is no correlation between the unique errors and the regressors in the model. The alternative hypothesis is that there is a correlation between the unique errors and the regressors in the model.
  
**$H_0$ = Both models are consistent**
**$H_a$ = One model is inconsistent**

  (b) Is the null hypothesis rejected? Based on the test, which model would you use?

```{r }

```

# Part 4 Simulate and Plot Correlation

Replicate the following figure which demonstrates the different levels of Pearson’s correlation.  
  
  *Hint*: Generate two variables with specific correlation (from -1 to 1) using `mvrnorm()` from the `MASS` package. 

![](corr_plot.png){width=100%}

```{r }

```

# Part 5 (Not Graded) Final Replication Project

At this point, you should complete the replication of Table A1a, Table A1b, and Figure 1, and about to finish the replication of the regression results (Table A2a and Table A2b). You should also be getting started on your project report. 

